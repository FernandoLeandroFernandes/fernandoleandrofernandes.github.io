:toc:
:source-highlighter: pygments

= PROCESSAMENTO DIGITAL DE IMAGENS (DCA0445)
FERNANDO LEANDRO FERNANDES <leandes@gmail.com>;GUSTAVO LINHARES GALVÃO <gustavolinhares1995@gmail.com>

== Apresentação

Esta página é destinada a postagem dos dos exercícios da disciplina de PROCESSAMENTO DIGITAL DE IMAGENS (DCA0445), ministrada pelo Professor Dr. Agostinho Brito Jr., do Departamento de Engenharia de Computação e Automação da Universidade Federal do Rio Grande do Norte - UFRN, no semestre de 2016.2.

Os programas foram implementados em liguagem C++, utilizando a biblioteca OpenCV versão 2.4.13 cuja instalação foi realizada utilizando o tutorial http://pythoneiro.blogspot.com.br/2014/11/instalando-opencv-no-linux-sem-dores-de.html[Instalando OpenCV no Linux sem dores de cabeça]. 

Optou-se pela ferramenta CMake para a compilação dos códigos.

== 3. Manipulação de pixels de uma imagem

=== Exercício 3.2.a - Negativo de uma região da imagem

O exercício 3.2.a pede para implementar um programa (regions.cpp) que solicite ao usuário as coordenadas de dois pontos P1 e P2 localizados dentro dos limites do tamanho da imagem que lhe for fornecida. A região definida pelo retângulo de vértices opostos definidos pelos pontos P1 e P2 será exibida com o negativo da imagem na região correspondente.

A implementação proposta recebe o nome do arquivo da imagem no parâmetro ''argv[1]'', abre-a, obtém as coordenadas os pontos P1 e P2 e procede à manipulação dos pixels da região delimitada pelos dois pontos informados. Para cada pixel calcula-se o seu inverso, p(x,y) = 255-p(x,y), onde p(x,y) refere-se ao pixel na linha x, coluna y. A listagem abaixo mostra o código que foi implementado.

[[app-listing]]
[source,cpp]
.regions.cpp
----
#include <iostream>
#include <highgui.h>
#include <cv.h>

using namespace std;
using namespace cv;

int main(int argc, char** argv) {

	Mat image;
	Vec3b val;
	int x1, x2, y1, y2, m;

	image= imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);

	if(!image.data) {
		cout << "Falha ao abrir " << argv[1] << "..." << endl;
		waitKey();
	}

	cout<<"Informe as coordenadas de P1 (x,y): ";
	cin>>x1>>y1;

	cout<<"Informe as coordenadas de P2 (x,y): ";
	cin>>x2>>y2;

	if(x1 > x2) {
		m = x2;
		x2 = x1;
		x1 = m;
	}

	if(y1 > y2) {
		m = y2;
		y2 = y1;
		y1 = m;
	}

	for(int i=x1; i < x2; i++){
		for(int j=y1; j < y2; j++){
			image.at<uchar>(i,j) -= -255;
		}
	}

	namedWindow("window", WINDOW_AUTOSIZE);

	imshow("window", image);

	imwrite("inverted.png", image);

	waitKey(3. );

	return 0;
}
----

Um teste de execução foi realizado com as coordenadas P1 (10, 50) e P2 (150, 80). O resultado pode ser observado na imagem abaixo.

image::images/inverted.png[Imagem produzida com a inversão]

=== Exercício 3.2.b - Trocar regiões da imagem

O exercício 3.2.b pede para implementar um programa (trocaregioes.cpp) que deverá trocar (reposicionar) aleatoriamente regiões da imagem, formando uma espécie de quebra-cabeças.

A implementação realizada obtém o nome do arquivo da imagem do parâmetro ''argv[1]'' fornecido na linha de comando, abre-a, randomiza um percentual da altura e da largura para a realização da separação das regiões. A listagem abaixo mostra o código que foi implementado.

[[app-listing]]
[source,cpp]
.trocaregioes.cpp
----
#include <iostream>
#include <cv.h>
#include <highgui.h>
#include <stdlib.h>
#include <time.h>

using namespace cv;
using namespace std;

int main(int argc, char** argv){

  Mat image;

  int width, height;

  image = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  if (!image.data) {
    cout << "Falha do abrir " << argv[1] << ", verifique o caminho para o aquivo." << endl;
    waitKey();
  }

  namedWindow("window",WINDOW_AUTOSIZE);

  width=image.size().width;
  cout<<"Largura: " << width << endl;

  height=image.size().height;
  cout<<"Altura: " << height << endl;

  Mat swapimage(height, width, CV_LOAD_IMAGE_GRAYSCALE);

  srand((unsigned) time(NULL));
  int point = rand()%(height < width ? height : width);

  for (int i = 0; i < height; i++) {
    for (int j = 0; j < width; j++) {
      swapimage.at<uchar>(i,j) = image.at<uchar>(((i+point) % height), ((j+point) % width));
    }
  }

  imshow("window", swapimage);

  imwrite("swapped.png",swapimage);

  waitKey();

  return 0;
}
----

Abaixo temos a imagem salva após a troca de regiões.

[[img-swapped]]
.Imagem resultado da troca de regiões
image::images/swapped.png[Imagem produzida com a troca de regiões]

== 4. Preenchendo regiões

=== Exercício 4.2.a - Rotulação com mais de 255 objetos

O exercício 4.2.a pede para que se identifique a situação em que ocorre problemas no processo de rotulação no programa labeling.cpp e apresentar uma solução para o problema de rotulação de mais regiões que a quantidade de valores disponível.

O programa labeling.cpp fornecido rotula cada objeto encontrado com um tom de cinza. Os computadores representam intensidade de brilho em valores que variam entre 0 e 255. Portanto, quando há mais do que 255 elementos a representar, o algoritmo  fica comprometido pela falta de níveis disponíveis para rotulação dos objetos restantes.

A solução proposta é a simples modulação da variável `bubbles`, que conta a quantidade de bolhas, pela quantidade de níveis possíveis, 255. Assim a contagem não é alterada e os valores de nível de cinza são atribuídos sem os problemas antes apresentados. O trecho de código abaixo implementa a solução proposta:

----
   floodFill(image, p, bubbles % 255);
----

=== Exercício 4.2.b - Contagem de bolhas

O exercício 4.2.b pede para que se aprimore o algoritmo de contagem apresentado (labeling.cpp) para identificar regiões com ou sem buracos internos que existam na cena.

A solução proposta é a simples modulação da variável `bubbles`, que conta a quantidade de bolhas, pela quantidade de níveis possíveis, 255. Assim a contagem não é alterada e os valores de nível de cinza são atribuídos sem os problemas antes apresentados. O trecho de código abaixo implementa a solução proposta:

[[app-listing]]
[source,cpp]
.bubblefill.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv) {

	int ORIGINAL_BGROUND = 0;
	int EXPLORED_BGROUND = 150;

	int ORIGINAL_BUBBLE = 255;
	int EXPLORED_BUBBLE = 152;

	Mat image, mask;
	CvPoint point;

	int width, height;
	int bubbles=0, holes=0;

	image = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);

	if(!image.data){
		cout << "Falha ao carregar a imagem " << argv[1] << "." << endl;
		return(-1);
	}

	width = image.size().width;
	height = image.size().height;

	// boder cleaning ----------------------------------------
	int k = 0;
	while (k < height) {

		point.y = k;

		point.x = 0;
		if (image.at<uchar>(point) == ORIGINAL_BUBBLE) {
			floodFill(image, point, ORIGINAL_BGROUND);
		}

		point.x = width-1;
		if (image.at<uchar>(point) == ORIGINAL_BUBBLE) {
			floodFill(image, point, ORIGINAL_BGROUND);
		}

		k++;
	}


	k = 1;
	while (k < width-1) {

		point.x = k;

		point.y = 0;
		if (image.at<uchar>(point) == ORIGINAL_BUBBLE) {
			floodFill(image, point, ORIGINAL_BGROUND);
		}

		point.y = height-1;
		if (image.at<uchar>(point) == ORIGINAL_BUBBLE) {
			floodFill(image, point, ORIGINAL_BGROUND);
		}

		k++;
	}


	// counting bubbles ----------------------------------------

	for(int i = 0; i < height; i++){
		for(int j = 0; j < width; j++){

			if (image.at<uchar>(i,j) == ORIGINAL_BUBBLE){
				bubbles++;
				point.x = j;
				point.y = i;
				floodFill(image, point, bubbles % 100);
			}
		}
	}

	// coloring the background ---------------------------------

	point.x=0;
	point.y=0;
	floodFill(image, point, EXPLORED_BGROUND);

	// counting the holes --------------------------------------

	int previouspix;

	for(int i = 0; i < height; i++){
		for(int j = 0; j < width; j++){

			if (image.at<uchar>(i,j) == ORIGINAL_BGROUND) {

				previouspix = image.at<uchar>(i,j-1);

				if (previouspix < 100) {
					holes++;
					point.x = j-1;
					point.y = i;
					floodFill(image, point, 255-previouspix);
				}

				point.x = j;
				point.y = i;
				floodFill(image, point, EXPLORED_BGROUND);
			}
		}
	}

	cout << "Bolhas solidas: "<< (bubbles - holes) <<"\n";
	cout << "Bolhas vazadas: "<< holes <<"\n";
	
	imshow("image", image);
	
	imwrite("bubblefill.png", image);
	
	waitKey();
	
	return 0;
}
----

Abaixo está mostrada a imagem salva após a contagem de bolhas, no caso, foram encontradas 21 bolhas sendo 7 delas vazadas.

[[img-bubblefill]]
.Imagem após o processamento de contagem de bolhas
image::images/bubblefill.png[Imagem produzida com contagem de bolhas]


== 5. Manipulação de histogramas

=== Exercício 5.2.a - Equalização do histograma

O exercício 5.2.a pede para que se implemente um programa (equalize.cpp) para equalizar o histograma para cada imagem capturada do vídeo de uma câmera que está conectada ao computador. É mostrado assim, duas janelas, sendo uma com imagens originais, e outra com as imagens contendo seu histograma já equalizado. As imagens são processadas em tons de cinza. A seguir está o código para esse programa, equalize.cpp.

[[app-listing]]
[source,cpp]
.equalize.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image;
  int width, height;
  VideoCapture cap;

  Mat histGray, histEqualized;
  Mat imageEqualized;

  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;


  cap.open(0);

  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }

  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;

  int histw = nbins, histh = nbins/2;

  Mat histImgGray(histh, histw,  CV_BGR2GRAY, Scalar(0,0,0));
  Mat histImgEqualized(histh, histw,  CV_BGR2GRAY, Scalar(0,0,0));

  while(1){
    cap >> image;

    cvtColor(image, image, CV_BGR2GRAY);

    calcHist(&image, 1, 0, Mat(), histGray, 1,
             &nbins, &histrange,
             uniform, acummulate);

    normalize(histGray, histGray, 0, histImgGray.rows, NORM_MINMAX, -1, Mat());

    histImgGray.setTo(Scalar(0));

    equalizeHist(image, imageEqualized);

    calcHist(&imageEqualized, 1, 0, Mat(), histEqualized, 1,
             &nbins, &histrange,
             uniform, acummulate);

    normalize(histEqualized, histEqualized, 0, histImgEqualized.rows, NORM_MINMAX, -1, Mat());

    histImgEqualized.setTo(Scalar(0));

     for(int i=0; i<nbins; i++){
      line(histImgGray, Point(i, histh),
           Point(i, cvRound(histGray.at<float>(i))),
           Scalar(255), 1, 8, 0);

      line(histImgEqualized, Point(i, histh),
           Point(i, cvRound(histEqualized.at<float>(i))),
           Scalar(255), 1, 8, 0);
      }

    histImgGray.copyTo(image(Rect(0, 0,nbins, histh)));

    histImgEqualized.copyTo(imageEqualized(Rect(0, 0,nbins, histh)));

    imshow("image", image);
    imshow("imageEqualized", imageEqualized);

    if(waitKey(30) >= 0) break;
  }
  return 0;
}
----

Cada pixel de uma imagem tem uma cor que foi produzida por uma combinação de cores primárias (vermelho, verde e azul, ou RGB). Cada uma dessas cores pode ter um brilho que varia de 0 a 255 em uma imagem digital com profundidade de bits de 8-bits. Um histograma RGB é produzido quando o computador varre a imagem em cada um desses valores de brilho RGB e conta quantos pixels há em cada nível de 0 a 255. Como o trabalho foi realizado com imagens processadas em tons de cinza, o histograma é apresentado de acordo com os níveis de cinza. Com o histograma calculado, é feito sua equalização.

Equalizar o histograma significa obter a máxima variância do histograma de uma imagem, obtendo assim uma imagem com o melhor contraste. O contraste é uma medida qualitativa e que está relacionada com a distribuição dos tons de cinza em uma imagem.

Para calcular o histograma foi utilizado a função calcHist. Foi calculado primeiramente o histograma para o vídeo contendo imagens originais. A variável que contém a matriz com as imagens originais se chama image, do tipo Mat. A variável que contém o histograma para as imagens originais se chama histGray, do tipo Mat. No algorítmo apresentado, a linha que corresponde ao que foi explicado anteriormente é a seguinte:

----
	calcHist(&image, 1, 0, Mat(), histGray, 1,
	&nbins, &histrange,
	uniform, acummulate);
----

Já tendo em posse o histograma calculado, para realizar a equalização deste histograma foi utilizado a função equalizeHist. O primeiro parâmetro dessa função trata-se de uma variável do tipo Mat. Essa variável contém a matriz da imagem a ser equalizada. Já o segundo parâmetro trata-se do resultado, isto é, a imagem equalizada. No algorítmo apresentado, a linha que corresponde ao que foi explicado anteriormente é a seguinte:

----
	equalizeHist(image, imageEqualized);
----

Após a equalização, é calculado o seu histograma:

----
	calcHist(&imageEqualized, 1, 0, Mat(), histEqualized, 1,
	&nbins, &histrange,
	uniform, acummulate);
----

A variável histEqualized é do tipo Mat. Ela contém o histograma da imagem já equalizada.

Com a imagem equalizada e seu histograma calculado, é mostrado duas janelas para comparação. Uma janela com o nome image, que trata-se do vídeo original, e a outra janela com o nome imageEqualized, que trata-se do vídeo com as imagens equalizadas. As imagens são mostradas através da função imshow().

----
	imshow("image", image);
	imshow("imageEqualized", imageEqualized);
----

Abaixo temos as imagens original e equalizada, resultado do processamento.

[[image-equalized]]
.Imagem original e equalizada, após o processamento.
image::images/imageEqualize1.png[Imagem equalizada]

No canto superior esquerdo é mostrado o histograma da imagem. É possível perceber que a imagem equalizada apresenta um maior contraste.

=== Exercício 5.2.b - Detecção de movimento

O exercício 5.2.b pede para que se implemente um programa (motiondetector.cpp) para detectar movimento através de uma câmera conectada ao computador. Este algoritmo funciona comparando o histograma da imagem capturada com o último histograma calculado. Se a diferença ultrapassar um limiar pré-estabelecido, um alarme é ativado. A seguir está o código para esse programa.

[[app-listing]]
[source,cpp]
.motiondetector.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

const string currentDateTime() {
    time_t now = time(0);
    struct tm  tstruct;
    char buf[80];
    tstruct = *localtime(&now);
    strftime(buf, sizeof(buf), "%Y-%m-%d.%X", &tstruct);

    return buf;
}


int main(int argc, char** argv){
  Mat image;
  int width, height;
  VideoCapture cap;
  vector<Mat> planes;
  Mat histB;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  Mat lastHist;
  double aux=0;

  cap.open(0);

  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }

  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;

  int histw = nbins, histh = nbins/2;
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));

  cap >> image;
  split (image, planes);
  calcHist(&planes[0], 1, 0, Mat(), lastHist, 1,
           &nbins, &histrange,
           uniform, acummulate);

  while(1){
    cap >> image;
    split (image, planes);
    calcHist(&planes[0], 1, 0, Mat(), histB, 1,
             &nbins, &histrange,
             uniform, acummulate);

    normalize(histB, histB, 0, histImgR.rows, NORM_MINMAX, -1, Mat());

    histImgR.setTo(Scalar(0));

    for(int i=0; i<nbins; i++){
      line(histImgR, Point(i, histh),
           Point(i, cvRound(histB.at<float>(i))),
           Scalar(255, 0, 0), 1, 8, 0);
    }

    double compare = compareHist(histB, lastHist, CV_COMP_INTERSECT);

    //CV_COMP_INTERSECT
    if(compare>(aux+34) || compare<(aux-34)){

      cout << "Movimento detectado: " << currentDateTime() << std::endl;
      cout<<endl;
    }

    histImgR.copyTo(image(Rect(0, 0,nbins, histh)));

    imshow("image", image);
    if(waitKey(30) >= 0) break;

    lastHist=histB;
    aux=compare;
  }
  return 0;
}
----

Esse programa foi feito o calculando primeiramente o histograma para a primeira imagem capturada e salvando-o na variável chamada lastHist, do tipo Mat.

----
	calcHist(&planes[0], 1, 0, Mat(), lastHist, 1,
	&nbins, &histrange,
	uniform, acummulate);
----

A seguir, em um loop infinito, é calculado o histograma da imagem capturada atual, salvando-o na variável histB, do tipo Mat.

----
	calcHist(&planes[0], 1, 0, Mat(), histB, 1,
	&nbins, &histrange,
	uniform, acummulate);
----

É criado uma variável do tipo double chamada compare. Essa variável recebe o valor que a função compareHist retorna. A função compareHist serve para comparar dois histogramas. No caso do algoritmo em questão, compara o histB com lastHist.

----
	double compare = compareHist(histB, lastHist, CV_COMP_INTERSECT);
----

A variável compare será calculada continuamente, para cada iteração do loop, sempre calculando a diferença entre o histograma atual e o histograma anterior. A variável aux serve para salvar o último valor da variável compare. Se a diferença entre compare e aux for maior que 34 ou menor que -34, é detectado o movimento e é salvado o dia e a hora do ocorrido.

----
	if(compare>(aux+34) || compare<(aux-34)){

	cout << "Movimento detectado: " << currentDateTime() << std::endl;
	cout<<endl;
	}
----

A função currentDateTime() serve para imprimir o dia e a hora atual.

----
	const string currentDateTime() {
	    time_t now = time(0);
	    struct tm  tstruct;
	    char buf[80];
	    tstruct = *localtime(&now);
	    strftime(buf, sizeof(buf), "%Y-%m-%d.%X", &tstruct);

	    return buf;
}
----

A variável lastHist, no final da iteração, recebe o valor de histB, e aux recebe o valor de compare, para assim, ao começar outra iteração, essas variáveis estarem com o valor anterior das respectivas variáveis.

----
	lastHist=histB;
	aux=compare;
----

A saída é mostrada a seguir:

[[image-motion1]]
.Movimento detectado, teste 1.
image::images/motion1.png[Motion 1]

[[image-motion2]]
.Movimento detectado, teste 2.
image::images/motion2.png[Motion 2]

Ao movimentar a mão, o prgrama detecta o movimento e salva o dia e a hora do evento.

== 6. Filtragem no domínio espacial I

=== Exercício 6.2.a - Filtro laplaciano do gaussiano

O exercício 6.2.a pede para que, utilizando o programa exemplos/filtroespacial.cpp como referência, implemente um programa laplgauss.cpp que deverá acrescentar mais uma funcionalidade ao exemplo fornecido, permitindo que seja calculado o laplaciano do gaussiano das imagens capturadas. Ao fim, comparar o resultado desse filtro com a simples aplicação do filtro laplaciano.

[[app-listing]]
[source,cpp]
.laplgauss.cpp
----
#include <cstdio>
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m){
	
	cout << "\nMascara atual\n";
	
	for(int i=0; i<m.size().height; i++){
		cout << "|\t";
		for(int j=0; j<m.size().width; j++){
			printf("%.2f\t", m.at<float>(i,j));
		}
		cout << "|\n";
	}

	cout << endl;
}

void print_menu(){

	cout << 
	    "\nPressione a tecla correspondente ao filtro desejado: \n"
		"c/C - Ativar/desativar modo modular\n"
		"m/M - Filtro mediano\n"
		"g/G - Filtro gaussano\n"
		"v/V - Filtro vertical\n"
		"h/H - Filtro horizontal\n"
		"l/L - Filtro laplaciano\n"
		"q/Q - Filtro laplaciano do gaussiano\n"
		"[ESC] - Sair\n\n";
}

int main(int argvc, char** argv){
	
	char const ESC_KEY = 27;

	VideoCapture video;

	video.open(0);

	if (!video.isOpened()) {
		return -1;
	}
	
	float average[] =	{
						1, 1, 1,
						1, 1, 1,
						1, 1, 1
						};
	Mat average_mask = Mat(3, 3, CV_32F, average);
	average_mask = average_mask * (1/9.0);

	float gauss[] = {
					1, 2, 1,
					2, 4, 2,
					1, 2, 1
					};
	Mat gauss_mask = Mat(3, 3, CV_32F, gauss);
	gauss_mask = gauss_mask * (1/16.0);

	float horizontal[] = {
						 -1, 0, 1,
						 -2, 0, 2,
						 -1, 0, 1
						 };
	Mat horizontal_mask = Mat(3, 3, CV_32F, horizontal);

	float vertical[] =	{
						-1,-2,-1,
						 0, 0, 0,
						 1, 2, 1
						};
	Mat vertical_mask = Mat(3, 3, CV_32F, vertical);

	float laplacian[]=	{
						 0,-1, 0,
						-1, 4,-1,
						 0,-1, 0,
						};
	Mat laplacian_mask = Mat(3, 3, CV_32F, laplacian);


	Mat mask = average_mask;

	Mat capture, frame, frame32f, frameFiltered, result;
	int absolut_mode = true;
	int additional_laplacian_step = false;
	int key;

	double width, height;
	width  = video.get(CV_CAP_PROP_FRAME_WIDTH);
	height = video.get(CV_CAP_PROP_FRAME_HEIGHT);
	cout << "largura=" << width << "\n";;
	cout << "altura =" << height<< "\n";;

	namedWindow("filtroespacial",1);

	print_menu();

	while (key != ESC_KEY) {
			
		video >> capture;

		// Manipulacoes do frame capturado
		cvtColor(capture, frame, CV_BGR2GRAY);
		flip(frame, frame, 1);
		imshow("original", frame);

		frame.convertTo(frame32f, CV_32F);

		// Aplica o filtro espacial selecionado (mask)		
		filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);
		
		if (additional_laplacian_step) {
			filter2D( frameFiltered, frameFiltered, frame32f.depth(), laplacian_mask, Point(1,1), 0);
		}

		if (absolut_mode) {
			frameFiltered = abs(frameFiltered);
		}

		frameFiltered.convertTo(result, CV_8U);
		
		imshow("filtroespacial", result);
		
		key = waitKey(10);

		if (key == 'c' || key == 'C' ||
			key == 'm' || key == 'M' ||
			key == 'g' || key == 'G' || 
			key == 'q' || key == 'Q' ||
			key == 'h' || key == 'H' ||
			key == 'v' || key == 'V' ||
			key == 'l' || key == 'L') {

			print_menu();

			if (key == 'c' || key == 'C') {
				absolut_mode = !absolut_mode;
				cout << "Modo absoluto " << (absolut_mode ? "ativado" : "desativado") << endl;

			} else if (key == 'm' || key == 'M') {
				mask = average_mask;
				additional_laplacian_step = false;
				cout << "Filtro da media ativado." << endl;

			} else if (key == 'g' || key == 'G') {
				mask = gauss_mask;
				additional_laplacian_step = false;
				cout << "Filtro gaussiano ativado." << endl;

			} else if (key == 'h' || key == 'H') {
				mask = horizontal_mask;
				additional_laplacian_step = false;
				cout << "Filtro da horizontal ativado." << endl;

			} else if (key == 'v' || key == 'V') {
				mask = vertical_mask;
				additional_laplacian_step = false;
				cout << "Filtro da vertical ativado." << endl;

			} else if (key == 'l' || key == 'L') {
				mask = laplacian_mask;
				additional_laplacian_step = false;
				cout << "Filtro da laplaciano ativado." << endl;

			} else if (key == 'q' || key == 'Q') {
				mask = gauss_mask;
				additional_laplacian_step = true;
				cout << "Filtro laplaciano do gaussiano ativado." << endl;

			}

			printmask(mask);
		}
	}
	return 0;
}
----

Abaixo as imagens produzidas com o processamento da imagem original. Destacamos que a opção de valores absolutos não surte efeito quando estão ativos os filtros da média ou gaussiano.

[[img-original]]
.Imagem original
image::images/original.png[Original]

[[img-gauss]]
.Imagem com filto gaussiano
image::images/gauss.png[Gauss]

[[img-media]]
.Imagem com filtro da média
image::images/media.png[Media]

[[img-vertical]]
.Imagem com filtro vertical
image::images/vertical.png[Vertical]

[[img-vertical-abs]]
.Imagem com filtro vertical (absoluto)
image::images/vertical-abs.png[Vertical absoluto]

[[img-horizontal]]
.Imagem com filtro horizontal
image::images/horizontal.png[Horizontal]

[[img-horizontal-abs]]
.Imagem com filtro horizontal (absoluto)
image::images/horizontal-abs.png[Horizontal absoluto]

[[img-laplaciano]]
.Imagem com filtro laplaciano
image::images/laplacian.png[Laplaciano]

[[img-laplaciano-abs]]
.Imagem com filtro laplaciano (absoluto)
image::images/laplacian-abs.png[Laplaciano absoluto]

[[img-laplacianogaussiano]]
.Imagem com filtro laplaciano do gaussiano
image::images/gaussian-laplacian.png[Laplaciano-Gaussiano]

[[img-laplacianogaussiano-abs]]
.Imagem com filtro horizontal (absoluto)
image::images/gaussian-laplacian-abs.png[Laplaciano-Gaussiano absoluto]

== 7. Filtragem no domínio espacial II

=== Exercício 7.2.a - Efeito tiltshift estático

O exercício 7.2.a pede para que, tomando como base o programa http://agostinhobritojr.github.io/tutoriais/pdi/exemplos/addweighted.cpp[addweighted.cpp], seja implementado um programa que simule o efeito de lentes tiltshift em imagens estáticas.  Três ajustes devem ser providos na tela da interface:

- um ajuste para regular a altura da região central que entrará em foco;

- um ajuste para regular a força de decaimento da região borrada;

- um ajuste para regular a posição vertical do centro da região que entrará em foco. 

Finalizado o programa, a imagem produzida deverá ser salva em arquivo.


[[app-listing]]
[source,cpp]
.tiltshift.cpp
----
----

=== Exercício 7.2.b - Efeito tiltshift dinâmico

O exercício 7.2.b pede para que seja implementado um programa que simule o efeito de lentes tiltshift em video. Os mesmos outros requisitos do exercício anterior se aplicam.

[[app-listing]]
[source,cpp]
.tiltshiftvideo.cpp
----
----
